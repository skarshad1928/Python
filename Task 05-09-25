ğŸ“ Task: Parallel CSV Downloader + Reader

Pick 3â€“5[ CSV datasets from Kaggle or any open sou](<../../../Desktop/DATA WARE HOUSE AND DATA MINING/archive>)rce (or create dummy CSVs yourself).
Example: sales.csv, customers.csv, orders.csv.

Write a Python program that does this:

Uses threading to read all CSV files in parallel.

Each thread should print:

"Started reading <filename>"

"Finished reading <filename>"

Store the data into a shared dictionary like:

data = {
    "sales.csv": <DataFrame>,
    "customers.csv": <DataFrame>
}


Use threading.Lock() to make sure only one thread writes to the dictionary at a time.

After all threads finish (join()), print:

Total rows in each DataFrame

Total combined rows across all files

Example Output (Your goal ğŸš€):
Started reading sales.csv
Started reading customers.csv
Started reading orders.csv
Finished reading sales.csv
Finished reading customers.csv
Finished reading orders.csv

âœ… All files loaded successfully

sales.csv â†’ 1000 rows
customers.csv â†’ 500 rows
orders.csv â†’ 2000 rows
TOTAL rows = 3500


âœ¨ What youâ€™ll learn by solving this:

Creating & starting threads

Using join() to wait for threads

Using Lock for safe shared access

Applying threading in a real analyst workflow